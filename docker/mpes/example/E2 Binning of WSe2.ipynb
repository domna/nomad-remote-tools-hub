{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning raw Multidimensional Photoemission Spectroscopy (MPES) data and converting it into the NeXus format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to generate xarray based h5 files from WSe2 trARPES measurement data as detailed in this [paper](https://www.nature.com/articles/s41597-020-00769-8) and how to generate a file in the standardised [MPES NeXus format](https://manual.nexusformat.org/classes/contributed_definitions/NXmpes.html#nxmpes) from it.\n",
    "Due to the size of the example file (~6GB) you need at least 20 GB of memory on your computer you're executing this example on. If you just want to have a look on how to convert a pre-binned xarray based h5 file into the NeXus format you may have a look at the simpler [Convert to NeXus example](./E1%20Convert%20to%20NeXus.ipynb), which has lower hardware requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download RAW data (trARPES data of WSe2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here, we just import `shutil` for extracting the downloaded zip archive and set the main file folder for holding the measurement data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "FDIR = f'{os.getcwd()}/Scan049_1'\n",
    "ECAL = f'{os.getcwd()}/energycal_2019_01_08'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the provided measurement files are rather large (~6GB), they are not directly provided with the example.\n",
    "You can [download](https://zenodo.org/record/6369728/files/WSe2.zip) it from zenodo. This may take some time. Place the file in the directory of this notebook afterwards. Under Linux, macOS and in a NORTH container you can directly use the cell below to download the file with curl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -o WSe2.zip \"https://zenodo.org/record/6369728/files/WSe2.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract the measurement files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.unpack_archive('WSe2.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning of measurement data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the necessary packages. For a manual on how to install this dependencies refer to the provided [INSTALL.md](./INSTALL.md) file. If you're running a pre-built docker container or working with the NORTH tools, these dependencies are already available for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpes import base as base, fprocessing as fp, analysis as aly\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from dask import compute\n",
    "import datetime as dt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial data binning for distortion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parp = fp.parallelHDF5Processor(folder=FDIR)\n",
    "parp.gather(identifier=r'/*.h5', file_sorting=True)\n",
    "len(parp.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parp.files = parp.files[0:50]\n",
    "axes = ['X', 'Y', 't']\n",
    "# Important to keep the whole detector area for the initial binning!\n",
    "bins = [512, 512, 300]\n",
    "ranges = [(0, 2048), (0, 2048), (64000, 68000)]\n",
    "parp.parallelBinning(axes=axes, nbins=bins, ranges=ranges, scheduler='threads', ret=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine correction landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = aly.MomentumCorrector(parp.combinedresult['binned'])\n",
    "mc.selectSlice2D(slice(165, 175), 2)\n",
    "mc.featureExtract(mc.slice, sigma=5, fwhm=10, sigma_radius=3)\n",
    "mc.view(points=mc.features, annotated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate thin plate spline symmetry correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.splineWarpEstimate(image=mc.slice, landmarks=mc.pouter_ord, include_center=True,\n",
    "                      iterative=False, interp_order=2, update=True)\n",
    "mc.view(image=mc.slice_transformed, annotated=True, points={'feats':mc.ptargs}, backend='bokeh', crosshair=True, radii=[75,110,150], crosshair_thickness=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.coordinateTransform(type='translation', xtrans=70., ytrans=70., keep=True)\n",
    "plt.imshow(mc.slice_transformed, origin='lower', cmap='terrain_r')\n",
    "plt.axvline(x=256)\n",
    "plt.axhline(y=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.coordinateTransform( type='rotation', angle=-5, center=(256., 256.), keep=True)\n",
    "plt.imshow(mc.slice_transformed, origin='lower', cmap='terrain_r')\n",
    "plt.axvline(x=256)\n",
    "plt.axhline(y=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Deformation field:\n",
    "subs = 20\n",
    "plt.scatter(mc.cdeform_field[::subs,::subs].ravel(), mc.rdeform_field[::subs,::subs].ravel(), c='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one high-symmetry point\n",
    "point_b = [252.,255.]\n",
    "# Pick the BZ center\n",
    "point_a = [308.,346.]\n",
    "# give the distance of the two in inverse Angstrom\n",
    "distance = np.pi*4/3/3.297\n",
    "# Momentum calibration assuming equal scaling along both x and y directions (equiscale=True)\n",
    "# Requirements : pixel coordinates of and the momentum space distance between two symmetry points, \n",
    "# plus the momentum coordinates\n",
    "# of one of the two points \n",
    "ext = mc.calibrate(mc.slice_transformed,\n",
    "                   point_from=point_a,\n",
    "                   point_to=point_b,\n",
    "                   dist=distance,\n",
    "                   equiscale=True,\n",
    "                   ret=['extent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.view(image=mc.slice_transformed, imkwds=ext)\n",
    "plt.xlabel('$k_x$', fontsize=15)\n",
    "plt.ylabel('$k_y$', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = ['t']\n",
    "bins = [1000]\n",
    "ranges = [(63000, 80000)]\n",
    "traces, tof = fp.extractEDC(folder=ECAL,\n",
    "                            axes=axes, bins=bins, ranges=ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voltages = np.arange(-12.2, -23.2, -1)\n",
    "ec = aly.EnergyCalibrator(biases=voltages, traces=traces, tof=tof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec.normalize(smooth=True, span=7, order=1)\n",
    "ec.view(traces=ec.traces_normed, xaxis=ec.tof, backend='bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = [(65000, 65200)]\n",
    "ec.addFeatures(traces=ec.traces_normed, refid=0, ranges=rg[0], infer_others=True, mode='append')\n",
    "ec.featranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec.featureExtract(traces=ec.traces_normed, ranges=ec.featranges)\n",
    "ec.view(traces=ec.traces_normed, peaks=ec.peaks, backend='bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate energy calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refid=5\n",
    "Eref=-1.3\n",
    "axs = ec.calibrate(ret='all', Eref=Eref, t=ec.tof, refid=refid)\n",
    "ec.view(traces=ec.traces_normed, xaxis=ec.calibration['axis'], backend='bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality of calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(voltages)):\n",
    "    plt.plot(ec.calibration['axis']-(voltages[i]-voltages[refid]), ec.traces_normed[i])\n",
    "plt.xlim([-15,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect calibration function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec.view(traces=ec.calibration['axis'][None,:], xaxis=ec.tof, backend='matplotlib', show_legend=False)\n",
    "plt.scatter(ec.peaks[:,0], ec.biases-ec.biases[refid]+Eref, s=50, c='k')\n",
    "plt.xlabel('Time-of-flight', fontsize=15)\n",
    "plt.ylabel('Energy (eV)', fontsize=15)\n",
    "plt.ylim([-8,6])\n",
    "plt.xlim([63400,69800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = fp.dataframeProcessor(datafolder=FDIR)\n",
    "dfp.read(source='folder', ftype='h5', timeStamps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply energy calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.appendEAxis(E0=ec.calibration['E0'], a=ec.calibration['coeffs'])\n",
    "dfp.edf.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply distortion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.applyKCorrection(type='tps_matrix',\n",
    "                     rdeform_field = mc.rdeform_field,\n",
    "                     cdeform_field = mc.cdeform_field,\n",
    "                     X='X', Y='Y', newX='Xm', newY='Ym')\n",
    "dfp.edf.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply momentum calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.appendKAxis(point_b[0], point_b[1], X='Xm', Y='Ym', rstart=parp.binranges[0][0],\n",
    "                cstart=parp.binranges[1][0],\n",
    "                rstep=parp.binsteps[0],\n",
    "                cstep=parp.binsteps[1],\n",
    "                fc=mc.calibration['coeffs'][0],\n",
    "                fr=mc.calibration['coeffs'][1])\n",
    "dfp.edf.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply pump-probe delay axis conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADCRange = (650, 6900)\n",
    "timeRange = (-100, 200)\n",
    "dfp.edf['delay'] = timeRange[0] + (dfp.edf['ADC']-ADCRange[0]) *\\\n",
    "    (timeRange[1] - timeRange[0])/(ADCRange[1]-ADCRange[0])\n",
    "dfp.edf.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin 4D data in transformed grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = ['kx', 'ky', 'E', 'delay']\n",
    "bins = [50, 50, 100, 21]\n",
    "ranges = [(-2, 2), (-2, 2), (-3, 2), (-110, 190)]\n",
    "# jittering of energy and ADC should best be done on the bin size of the hardware, \n",
    "# not the rebinned bin size\n",
    "TOFrange=[64500,67000]\n",
    "e_t_conversion = (base.tof2evpoly(ec.calibration['coeffs'],\n",
    "                                  ec.calibration['E0'], \n",
    "                                  TOFrange[0])\n",
    "                  - base.tof2evpoly(ec.calibration['coeffs'],\n",
    "                                    ec.calibration['E0'], TOFrange[1])\n",
    "                 ) / (TOFrange[1] - TOFrange[0])\n",
    "d_adc_conversion = (timeRange[1] - timeRange[0]) / (ADCRange[1] - ADCRange[0])\n",
    "jitter_amplitude = [0.5,\n",
    "                    0.5,\n",
    "                    1*bins[2]/abs(ranges[2][1]-ranges[2][0])*e_t_conversion,\n",
    "                    1*bins[3]/abs(ranges[3][1]-ranges[3][0])*d_adc_conversion]\n",
    "dfp.distributedBinning(axes=axes,\n",
    "                       nbins=bins,\n",
    "                       ranges=ranges,\n",
    "                       scheduler='threads',\n",
    "                       ret=False,\n",
    "                       jittered=True,\n",
    "                       jitter_amplitude=jitter_amplitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create metatada structure\n",
    "This adds additional metadata to the h5 file. This data may also be provided through additional ELN entries through a NOMAD instance or with a handwriten file directly to the mpes parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual Meta data\n",
    "#General\n",
    "metadata['experiment_summary'] = 'WSe2 XUV NIR pump probe data.'\n",
    "metadata['entry_title'] = 'Valence Band Dynamics - 800 nm linear s-polarized pump, 0.6 mJ/cm2 absorbed fluence'\n",
    "metadata['experiment_title'] = 'Valence band dynamics of 2H-WSe2'\n",
    "\n",
    "#User\n",
    "# Fill general parameters of NXuser\n",
    "# TODO: discuss how to deal with multiple users?\n",
    "metadata['user0'] = {}\n",
    "metadata['user0']['name'] = 'Julian Maklar'\n",
    "metadata['user0']['role'] = 'Principal Investigator'\n",
    "metadata['user0']['affiliation'] = 'Fritz Haber Institute of the Max Planck Society'\n",
    "metadata['user0']['address'] = 'Faradayweg 4-6, 14195 Berlin'\n",
    "metadata['user0']['email'] = 'maklar@fhi-berlin.mpg.de'\n",
    "\n",
    "#NXinstrument\n",
    "metadata['instrument'] = {}\n",
    "#analyzer\n",
    "metadata['instrument']['analyzer']={}\n",
    "metadata['instrument']['analyzer']['slow_axes'] = \"delay\" # the scanned axes\n",
    "metadata['instrument']['analyzer']['spatial_resolution'] = 10.\n",
    "metadata['instrument']['analyzer']['energy_resolution'] = 110.\n",
    "metadata['instrument']['analyzer']['momentum_resolution'] = 0.08\n",
    "metadata['instrument']['analyzer']['projection'] = \"reciprocal\"\n",
    "metadata['instrument']['analyzer']['working_distance'] = 4.\n",
    "metadata['instrument']['analyzer']['lens_mode'] = \"6kV_kmodem4.0_30VTOF.sav\"\n",
    "\n",
    "# Need to get those from the data file...\n",
    "# Put into separate Lens objects?\n",
    "# metadata['instrument']['analyzer']['fa_size'] = 200\n",
    "# metadata['instrument']['analyzer']['ca_size'] = np.nan\n",
    "\n",
    "#probe beam\n",
    "metadata['instrument']['beam']={}\n",
    "metadata['instrument']['beam']['probe']={}\n",
    "metadata['instrument']['beam']['probe']['incident_energy'] = 21.7\n",
    "metadata['instrument']['beam']['probe']['incident_energy_spread'] = 0.11\n",
    "metadata['instrument']['beam']['probe']['pulse_duration'] = 20.\n",
    "metadata['instrument']['beam']['probe']['frequency'] = 500.\n",
    "metadata['instrument']['beam']['probe']['incident_polarization'] = [1, 1, 0, 0] # p pol Stokes vector\n",
    "metadata['instrument']['beam']['probe']['extent'] = [80., 80.] \n",
    "#pump beam\n",
    "metadata['instrument']['beam']['pump']={}\n",
    "metadata['instrument']['beam']['pump']['incident_energy'] = 1.55\n",
    "metadata['instrument']['beam']['pump']['incident_energy_spread'] = 0.08\n",
    "metadata['instrument']['beam']['pump']['pulse_duration'] = 35.\n",
    "metadata['instrument']['beam']['pump']['frequency'] = 500.\n",
    "metadata['instrument']['beam']['pump']['incident_polarization'] = [1, -1, 0, 0] # s pol Stokes vector\n",
    "metadata['instrument']['beam']['pump']['incident_wavelength'] = 800. \n",
    "metadata['instrument']['beam']['pump']['average_power'] = 300.\n",
    "metadata['instrument']['beam']['pump']['pulse_energy'] = metadata['instrument']['beam']['pump']['average_power']/metadata['instrument']['beam']['pump']['frequency']#ÂµJ\n",
    "metadata['instrument']['beam']['pump']['extent'] = [230., 265.] \n",
    "metadata['instrument']['beam']['pump']['fluence'] = 0.15\n",
    "\n",
    "#sample\n",
    "metadata['sample']={}\n",
    "metadata['sample']['preparation_date'] = '2019-01-13T10:00:00+00:00'\n",
    "metadata['sample']['sample_history'] = 'Cleaved'\n",
    "metadata['sample']['chemical_formula'] = 'WSe2'\n",
    "metadata['sample']['description'] = 'Sample'\n",
    "metadata['sample']['name'] = 'WSe2 Single Crystal'\n",
    "# metadata['sample']['temperature'] = 300.\n",
    "# metadata['sample']['pressure'] = 5.e-11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert and save as h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_xarray = dfp.gather_metadata(metadata_dict=metadata.copy(), ec=ec, mc=mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.xarray_to_h5(res_xarray, \"WSe2_xarray.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convert the generated file into the NeXus format\n",
    "This conversion basically follows the same procedure as in the [convert to NeXus example](./E1%20Convert%20to%20Nexus.ipynb). Please refer to this notebook for details on the convert function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nexusparser.tools.dataconverter.convert import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert(input_file=[\"WSe2_xarray.h5\",\"config_file.json\",\"ELN_metadata_example.yaml\"],\n",
    "        reader='mpes',\n",
    "        nxdl='NXmpes',\n",
    "        output='WSe2.mpes.nxs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## View the data with H5Web\n",
    "H5Web is a tool for visualizing any data in the h5 data format. Since the NeXus format builds opon h5 it can be used to view this data as well. We just import the package and call H5Web with the output filename from the convert command above. For an analysis on NeXus data files please refer to [analysis example](./E3%20pyARPES%20analysis.ipynb).\n",
    "\n",
    "You can also view this data with the H5Viewer or other tools from your local filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterlab_h5web import H5Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H5Web('WSe2.mpes.nxs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
